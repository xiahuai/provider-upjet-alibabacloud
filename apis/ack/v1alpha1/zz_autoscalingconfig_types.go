// SPDX-FileCopyrightText: 2024 The Crossplane Authors <https://crossplane.io>
//
// SPDX-License-Identifier: Apache-2.0

// Code generated by upjet. DO NOT EDIT.

package v1alpha1

import (
	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
	"k8s.io/apimachinery/pkg/runtime/schema"

	v1 "github.com/crossplane/crossplane-runtime/apis/common/v1"
)

type AutoscalingConfigInitParameters struct {

	// The id of kubernetes cluster.
	// +crossplane:generate:reference:type=github.com/crossplane-contrib/provider-alibabacloud/apis/ack/v1alpha1.ManagedKubernetes
	// +crossplane:generate:reference:refFieldName=ClusterIDRefs
	// +crossplane:generate:reference:selectorFieldName=ClusterIDSelector
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// Reference to a ManagedKubernetes in ack to populate clusterId.
	// +kubebuilder:validation:Optional
	ClusterIDRefs *v1.Reference `json:"clusterIdRefs,omitempty" tf:"-"`

	// Selector for a ManagedKubernetes in ack to populate clusterId.
	// +kubebuilder:validation:Optional
	ClusterIDSelector *v1.Selector `json:"clusterIdSelector,omitempty" tf:"-"`

	// The cool down duration. Default is 10m. If the delay (cooldown) value is set too long, there could be complaints that the Horizontal Pod Autoscaler is not responsive to workload changes. However, if the delay value is set too short, the scale of the replicas set may keep thrashing as usual.
	CoolDownDuration *string `json:"coolDownDuration,omitempty" tf:"cool_down_duration,omitempty"`

	// If true DaemonSet pods will be  terminated from nodes. Default is false.
	DaemonsetEvictionForNodes *bool `json:"daemonsetEvictionForNodes,omitempty" tf:"daemonset_eviction_for_nodes,omitempty"`

	// The policy for selecting which node pool to scale. Valid values: least-waste, random, priority. For more information on these policies, see Configure auto scaling
	Expander *string `json:"expander,omitempty" tf:"expander,omitempty"`

	// The scale-in threshold for GPU instance. Default is 0.5.
	GpuUtilizationThreshold *string `json:"gpuUtilizationThreshold,omitempty" tf:"gpu_utilization_threshold,omitempty"`

	// Maximum number of seconds CA waits for pod termination when trying to scale down a node. Default is 14400.
	MaxGracefulTerminationSec *float64 `json:"maxGracefulTerminationSec,omitempty" tf:"max_graceful_termination_sec,omitempty"`

	// Minimum number of replicas that a replica set or replication controller should have to allow their pods deletion in scale down. Default is 0.
	MinReplicaCount *float64 `json:"minReplicaCount,omitempty" tf:"min_replica_count,omitempty"`

	// Should CA delete the K8s node object when recycle node has scaled down successfully. Default is false.
	RecycleNodeDeletionEnabled *bool `json:"recycleNodeDeletionEnabled,omitempty" tf:"recycle_node_deletion_enabled,omitempty"`

	// Specify whether to allow the scale-in of nodes. Default is true.
	ScaleDownEnabled *bool `json:"scaleDownEnabled,omitempty" tf:"scale_down_enabled,omitempty"`

	// Should CA scale up when there 0 ready nodes. Default is true.
	ScaleUpFromZero *bool `json:"scaleUpFromZero,omitempty" tf:"scale_up_from_zero,omitempty"`

	// The type of autoscaler. Valid values: cluster-autoscaler, goatscaler. For cluster version 1.22 and below, we only support cluster-autoscaler.
	ScalerType *string `json:"scalerType,omitempty" tf:"scaler_type,omitempty"`

	// The interval at which the cluster is reevaluated for scaling. Default is 30s.
	ScanInterval *string `json:"scanInterval,omitempty" tf:"scan_interval,omitempty"`

	// If true cluster autoscaler will never delete nodes with pods with local storage, e.g. EmptyDir or HostPath. Default is false.
	SkipNodesWithLocalStorage *bool `json:"skipNodesWithLocalStorage,omitempty" tf:"skip_nodes_with_local_storage,omitempty"`

	// If true cluster autoscaler will never delete nodes with pods from kube-system (except for DaemonSet or mirror pods). Default is true.
	SkipNodesWithSystemPods *bool `json:"skipNodesWithSystemPods,omitempty" tf:"skip_nodes_with_system_pods,omitempty"`

	// The unneeded duration. Default is 10m.
	UnneededDuration *string `json:"unneededDuration,omitempty" tf:"unneeded_duration,omitempty"`

	// The scale-in threshold. Default is 0.5.
	UtilizationThreshold *string `json:"utilizationThreshold,omitempty" tf:"utilization_threshold,omitempty"`
}

type AutoscalingConfigObservation struct {

	// The id of kubernetes cluster.
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// The cool down duration. Default is 10m. If the delay (cooldown) value is set too long, there could be complaints that the Horizontal Pod Autoscaler is not responsive to workload changes. However, if the delay value is set too short, the scale of the replicas set may keep thrashing as usual.
	CoolDownDuration *string `json:"coolDownDuration,omitempty" tf:"cool_down_duration,omitempty"`

	// If true DaemonSet pods will be  terminated from nodes. Default is false.
	DaemonsetEvictionForNodes *bool `json:"daemonsetEvictionForNodes,omitempty" tf:"daemonset_eviction_for_nodes,omitempty"`

	// The policy for selecting which node pool to scale. Valid values: least-waste, random, priority. For more information on these policies, see Configure auto scaling
	Expander *string `json:"expander,omitempty" tf:"expander,omitempty"`

	// The scale-in threshold for GPU instance. Default is 0.5.
	GpuUtilizationThreshold *string `json:"gpuUtilizationThreshold,omitempty" tf:"gpu_utilization_threshold,omitempty"`

	// Resource id.
	ID *string `json:"id,omitempty" tf:"id,omitempty"`

	// Maximum number of seconds CA waits for pod termination when trying to scale down a node. Default is 14400.
	MaxGracefulTerminationSec *float64 `json:"maxGracefulTerminationSec,omitempty" tf:"max_graceful_termination_sec,omitempty"`

	// Minimum number of replicas that a replica set or replication controller should have to allow their pods deletion in scale down. Default is 0.
	MinReplicaCount *float64 `json:"minReplicaCount,omitempty" tf:"min_replica_count,omitempty"`

	// Should CA delete the K8s node object when recycle node has scaled down successfully. Default is false.
	RecycleNodeDeletionEnabled *bool `json:"recycleNodeDeletionEnabled,omitempty" tf:"recycle_node_deletion_enabled,omitempty"`

	// Specify whether to allow the scale-in of nodes. Default is true.
	ScaleDownEnabled *bool `json:"scaleDownEnabled,omitempty" tf:"scale_down_enabled,omitempty"`

	// Should CA scale up when there 0 ready nodes. Default is true.
	ScaleUpFromZero *bool `json:"scaleUpFromZero,omitempty" tf:"scale_up_from_zero,omitempty"`

	// The type of autoscaler. Valid values: cluster-autoscaler, goatscaler. For cluster version 1.22 and below, we only support cluster-autoscaler.
	ScalerType *string `json:"scalerType,omitempty" tf:"scaler_type,omitempty"`

	// The interval at which the cluster is reevaluated for scaling. Default is 30s.
	ScanInterval *string `json:"scanInterval,omitempty" tf:"scan_interval,omitempty"`

	// If true cluster autoscaler will never delete nodes with pods with local storage, e.g. EmptyDir or HostPath. Default is false.
	SkipNodesWithLocalStorage *bool `json:"skipNodesWithLocalStorage,omitempty" tf:"skip_nodes_with_local_storage,omitempty"`

	// If true cluster autoscaler will never delete nodes with pods from kube-system (except for DaemonSet or mirror pods). Default is true.
	SkipNodesWithSystemPods *bool `json:"skipNodesWithSystemPods,omitempty" tf:"skip_nodes_with_system_pods,omitempty"`

	// The unneeded duration. Default is 10m.
	UnneededDuration *string `json:"unneededDuration,omitempty" tf:"unneeded_duration,omitempty"`

	// The scale-in threshold. Default is 0.5.
	UtilizationThreshold *string `json:"utilizationThreshold,omitempty" tf:"utilization_threshold,omitempty"`
}

type AutoscalingConfigParameters struct {

	// The id of kubernetes cluster.
	// +crossplane:generate:reference:type=github.com/crossplane-contrib/provider-alibabacloud/apis/ack/v1alpha1.ManagedKubernetes
	// +crossplane:generate:reference:refFieldName=ClusterIDRefs
	// +crossplane:generate:reference:selectorFieldName=ClusterIDSelector
	// +kubebuilder:validation:Optional
	ClusterID *string `json:"clusterId,omitempty" tf:"cluster_id,omitempty"`

	// Reference to a ManagedKubernetes in ack to populate clusterId.
	// +kubebuilder:validation:Optional
	ClusterIDRefs *v1.Reference `json:"clusterIdRefs,omitempty" tf:"-"`

	// Selector for a ManagedKubernetes in ack to populate clusterId.
	// +kubebuilder:validation:Optional
	ClusterIDSelector *v1.Selector `json:"clusterIdSelector,omitempty" tf:"-"`

	// The cool down duration. Default is 10m. If the delay (cooldown) value is set too long, there could be complaints that the Horizontal Pod Autoscaler is not responsive to workload changes. However, if the delay value is set too short, the scale of the replicas set may keep thrashing as usual.
	// +kubebuilder:validation:Optional
	CoolDownDuration *string `json:"coolDownDuration,omitempty" tf:"cool_down_duration,omitempty"`

	// If true DaemonSet pods will be  terminated from nodes. Default is false.
	// +kubebuilder:validation:Optional
	DaemonsetEvictionForNodes *bool `json:"daemonsetEvictionForNodes,omitempty" tf:"daemonset_eviction_for_nodes,omitempty"`

	// The policy for selecting which node pool to scale. Valid values: least-waste, random, priority. For more information on these policies, see Configure auto scaling
	// +kubebuilder:validation:Optional
	Expander *string `json:"expander,omitempty" tf:"expander,omitempty"`

	// The scale-in threshold for GPU instance. Default is 0.5.
	// +kubebuilder:validation:Optional
	GpuUtilizationThreshold *string `json:"gpuUtilizationThreshold,omitempty" tf:"gpu_utilization_threshold,omitempty"`

	// Maximum number of seconds CA waits for pod termination when trying to scale down a node. Default is 14400.
	// +kubebuilder:validation:Optional
	MaxGracefulTerminationSec *float64 `json:"maxGracefulTerminationSec,omitempty" tf:"max_graceful_termination_sec,omitempty"`

	// Minimum number of replicas that a replica set or replication controller should have to allow their pods deletion in scale down. Default is 0.
	// +kubebuilder:validation:Optional
	MinReplicaCount *float64 `json:"minReplicaCount,omitempty" tf:"min_replica_count,omitempty"`

	// Should CA delete the K8s node object when recycle node has scaled down successfully. Default is false.
	// +kubebuilder:validation:Optional
	RecycleNodeDeletionEnabled *bool `json:"recycleNodeDeletionEnabled,omitempty" tf:"recycle_node_deletion_enabled,omitempty"`

	// Region is the region you'd like your resource to be created in.
	// +upjet:crd:field:TFTag=-
	// +kubebuilder:validation:Optional
	Region *string `json:"region,omitempty" tf:"-"`

	// Specify whether to allow the scale-in of nodes. Default is true.
	// +kubebuilder:validation:Optional
	ScaleDownEnabled *bool `json:"scaleDownEnabled,omitempty" tf:"scale_down_enabled,omitempty"`

	// Should CA scale up when there 0 ready nodes. Default is true.
	// +kubebuilder:validation:Optional
	ScaleUpFromZero *bool `json:"scaleUpFromZero,omitempty" tf:"scale_up_from_zero,omitempty"`

	// The type of autoscaler. Valid values: cluster-autoscaler, goatscaler. For cluster version 1.22 and below, we only support cluster-autoscaler.
	// +kubebuilder:validation:Optional
	ScalerType *string `json:"scalerType,omitempty" tf:"scaler_type,omitempty"`

	// The interval at which the cluster is reevaluated for scaling. Default is 30s.
	// +kubebuilder:validation:Optional
	ScanInterval *string `json:"scanInterval,omitempty" tf:"scan_interval,omitempty"`

	// If true cluster autoscaler will never delete nodes with pods with local storage, e.g. EmptyDir or HostPath. Default is false.
	// +kubebuilder:validation:Optional
	SkipNodesWithLocalStorage *bool `json:"skipNodesWithLocalStorage,omitempty" tf:"skip_nodes_with_local_storage,omitempty"`

	// If true cluster autoscaler will never delete nodes with pods from kube-system (except for DaemonSet or mirror pods). Default is true.
	// +kubebuilder:validation:Optional
	SkipNodesWithSystemPods *bool `json:"skipNodesWithSystemPods,omitempty" tf:"skip_nodes_with_system_pods,omitempty"`

	// The unneeded duration. Default is 10m.
	// +kubebuilder:validation:Optional
	UnneededDuration *string `json:"unneededDuration,omitempty" tf:"unneeded_duration,omitempty"`

	// The scale-in threshold. Default is 0.5.
	// +kubebuilder:validation:Optional
	UtilizationThreshold *string `json:"utilizationThreshold,omitempty" tf:"utilization_threshold,omitempty"`
}

// AutoscalingConfigSpec defines the desired state of AutoscalingConfig
type AutoscalingConfigSpec struct {
	v1.ResourceSpec `json:",inline"`
	ForProvider     AutoscalingConfigParameters `json:"forProvider"`
	// THIS IS A BETA FIELD. It will be honored
	// unless the Management Policies feature flag is disabled.
	// InitProvider holds the same fields as ForProvider, with the exception
	// of Identifier and other resource reference fields. The fields that are
	// in InitProvider are merged into ForProvider when the resource is created.
	// The same fields are also added to the terraform ignore_changes hook, to
	// avoid updating them after creation. This is useful for fields that are
	// required on creation, but we do not desire to update them after creation,
	// for example because of an external controller is managing them, like an
	// autoscaler.
	InitProvider AutoscalingConfigInitParameters `json:"initProvider,omitempty"`
}

// AutoscalingConfigStatus defines the observed state of AutoscalingConfig.
type AutoscalingConfigStatus struct {
	v1.ResourceStatus `json:",inline"`
	AtProvider        AutoscalingConfigObservation `json:"atProvider,omitempty"`
}

// +kubebuilder:object:root=true
// +kubebuilder:subresource:status
// +kubebuilder:storageversion

// AutoscalingConfig is the Schema for the AutoscalingConfigs API. Provides a Alicloud resource to configure auto scaling for for ACK cluster.
// +kubebuilder:printcolumn:name="SYNCED",type="string",JSONPath=".status.conditions[?(@.type=='Synced')].status"
// +kubebuilder:printcolumn:name="READY",type="string",JSONPath=".status.conditions[?(@.type=='Ready')].status"
// +kubebuilder:printcolumn:name="EXTERNAL-NAME",type="string",JSONPath=".metadata.annotations.crossplane\\.io/external-name"
// +kubebuilder:printcolumn:name="AGE",type="date",JSONPath=".metadata.creationTimestamp"
// +kubebuilder:resource:scope=Cluster,categories={crossplane,managed,alibabacloud}
type AutoscalingConfig struct {
	metav1.TypeMeta   `json:",inline"`
	metav1.ObjectMeta `json:"metadata,omitempty"`
	Spec              AutoscalingConfigSpec   `json:"spec"`
	Status            AutoscalingConfigStatus `json:"status,omitempty"`
}

// +kubebuilder:object:root=true

// AutoscalingConfigList contains a list of AutoscalingConfigs
type AutoscalingConfigList struct {
	metav1.TypeMeta `json:",inline"`
	metav1.ListMeta `json:"metadata,omitempty"`
	Items           []AutoscalingConfig `json:"items"`
}

// Repository type metadata.
var (
	AutoscalingConfig_Kind             = "AutoscalingConfig"
	AutoscalingConfig_GroupKind        = schema.GroupKind{Group: CRDGroup, Kind: AutoscalingConfig_Kind}.String()
	AutoscalingConfig_KindAPIVersion   = AutoscalingConfig_Kind + "." + CRDGroupVersion.String()
	AutoscalingConfig_GroupVersionKind = CRDGroupVersion.WithKind(AutoscalingConfig_Kind)
)

func init() {
	SchemeBuilder.Register(&AutoscalingConfig{}, &AutoscalingConfigList{})
}
